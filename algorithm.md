## **Waste Sorting Station: User Algorithm of Action**

---

### **Step 1: Arrival and Initial Setup**
1. **User approaches the station** with bags of waste containing **textile, e-waste, paper, cardboard, glass, plastics, and metal**.
2. The station **welcomes the user via an audio prompt** and display shows sorting categories and basic instructions.

### **Step 2: Waste Identification Process**
The stationâ€™s **camera with AI image recognition** will scan each item as the user presents it in front of the camera or places it on the sorting surface.

### **Step 3: Sorting cycle**
1. **User presents the item** by holding it under the camera or placing it in the **General Item Sorting Table**.
2. **Camera and AI system** analyze the object, identifying its shape, material, and category (plastic, metal, textile, etc.).
3. **If the item is ambiguous**, the system may request the user to place it in the designated area for further analysis or to use additional sensors.

---

### **Sorting Specific Types of Waste**

---

[Paper and cardboard](./paper%20and%20cardoard.md)

---

[Plastics](./plastics.md)

---

[Metal](./metals.md)

---

[Glass](./glass.md)

---

[Textile](./textile.md)

---

[E-Waste](./e-waste.md)

---

### **Step 4: System Feedback**
1. **The station provides feedback** after each item is sorted, confirming the correct action (e.g., "Thank you for sorting metal!" or "Please remove the cap from this bottle").
2. If the system is uncertain about the material (e.g., complex electronics), it may ask the user to confirm the item type or offer additional guidance.

---

### **Step 5: User Finishes Sorting**
1. Once all items have been sorted, the station **thanks the user** and provides a summary of the sorted waste (optional: show environmental impact) and rewards user with eco/green points in Pfand-like scheme, in parallel it also sends data to the central server about amount and types of collected resources.
2. **Optional Feedback**: The user could be invited to leave feedback on the process

---

### **Important**: 
At any moment, if the user feels stuck or doesn't understand, he/she can simply ask the machine about the process or next step, the system will listen to that question through microphones, record the question, and send it to either **AGI** or human operator, receive the answer and show it on display and voice it through speakers.

---